{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"2019.11.02. 5.6 Basic CNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"5Qr5GcTRAQJO","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.init as init\n","\n","# data set\n","import torchvision.datasets as dset\n","\n","# image transform kit\n","import torchvision.transforms as transforms\n","\n","# 전처리가 끝난 데이터를 지정한 배치 크기에 맞게 모아서 전달하는 역할\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTACGCcjFTCy","colab_type":"code","colab":{},"outputId":"d4041184-e18b-4351-e04e-9eb33a83aa4f"},"source":["torch.Tensor([1, 2]).type()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'torch.FloatTensor'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IYY8udZEAxxf"},"source":["## hyper parameter"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1ItrV80mA5Ou","colab":{}},"source":["batch_size = 256\n","learning_rate = 0.0002\n","num_epoch = 10"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"77kx3zYZA88j"},"source":["## data download"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":12054,"status":"ok","timestamp":1572663487188,"user":{"displayName":"김태웅","photoUrl":"","userId":"06196795162879697734"},"user_tz":-540},"id":"9_R8x6vCBKIb","outputId":"efe612f7-dce1-451a-ca47-e70013380d78","colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["# root = data save location\n","# train = 학습용 데이터면 true 아니면 False(True = Train, False = Test)\n","\n","# trainsfrom = 이미지 변형\n","# target_fransform = 정답 라벨에 대한 변형\n","# transform_ToTensor = PIL image or Numpy arrange를 torch Tensor로 바꿔줌\n","# download = 현재 경로에 데이터가 없을 경우 추가로 다운도 받을지 여부\n","mnist_train = dset.MNIST(root=\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n","mnist_test = dset.MNIST(root=\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["9920512it [00:07, 1291121.44it/s]                             \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"],"name":"stdout"},{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 57569.43it/s]                           \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["1654784it [00:01, 1073318.41it/s]                           \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["8192it [00:00, 21852.17it/s]            \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ke4-Hh-xC2jW"},"source":["## DataSet Check"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":765,"status":"ok","timestamp":1572663660132,"user":{"displayName":"김태웅","photoUrl":"","userId":"06196795162879697734"},"user_tz":-540},"id":"BOBNl0lGDlMb","outputId":"be3b6f8f-f80a-4c04-b2d0-6975390bf4b8","colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["mnist_train.__getitem__"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method MNIST.__getitem__ of Dataset MNIST\n","    Number of datapoints: 60000\n","    Root location: ./\n","    Split: Train\n","    StandardTransform\n","Transform: ToTensor()>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1328,"status":"ok","timestamp":1572663756775,"user":{"displayName":"김태웅","photoUrl":"","userId":"06196795162879697734"},"user_tz":-540},"id":"j6KKnp7uDwsb","outputId":"1f6335b6-1c25-48eb-e94b-72eec4f615a3","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["mnist_train.__getitem__(0)[0].size(), len(mnist_train)\n","mnist_train.__getitem__(0)[0].size(), len(mnist_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 28, 28]), 60000)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1389,"status":"ok","timestamp":1572663791533,"user":{"displayName":"김태웅","photoUrl":"","userId":"06196795162879697734"},"user_tz":-540},"id":"Ndis0lj-EIJj","outputId":"b65c1bb8-7e50-449a-deb1-38150b1066f3","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["mnist_train[0][0].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 28, 28])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jFNCIL65EQPi"},"source":["## DataSet settings"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IXp18qtnQLkm","colab":{}},"source":["# 데이터 증강\n","'''mnist_train = dset.MNIST(\"./\", train=True, \n","                         transform = transforms.Compose([\n","                             transforms.Resize(34),                             # 원래 28x28인 이미지를 34x34로 늘립니다.\n","                             transforms.CenterCrop(28),                         # 중앙 28x28를 뽑아냅니다.\n","                             transforms.RandomHorizontalFlip(),                 # 랜덤하게 좌우반전 합니다.\n","                             transforms.Lambda(lambda x: x.rotate(90)),         # 람다함수를 이용해 90도 회전해줍니다.\n","                             transforms.ToTensor(),                             # 이미지를 텐서로 변형합니다.\n","                         ]),\n","                         target_transform=None,\n","                         download=True)'''\n","\n","# data trainform\n","'''transfroms.Compose([\n","                    transforms.Normalize(mean=(0.1307,), std=(0.3081,))])\n","                    를 넣어주면 됨, RGB면\n","                    mean = (0.1307, 0.1364, 0.1354), std도 3개'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eMAmmY5YEbzL","colab":{}},"source":["# batch_size = 256\n","# 배치사이즈 정해주고 섞고 사용할 프로세스 갯수 적고 마지막 남는\n","# 데이터 처리 여부(True면 배치 단위로 안 끊어지는 마지막 데이터 삭제)\n","train_loader = DataLoader(mnist_train, batch_size = batch_size, shuffle = True, \n","                          num_workers = 2, drop_last = True)\n","test_loader = DataLoader(mnist_train, batch_size = batch_size, shuffle = False, \n","                          num_workers = 2, drop_last = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cT59VMI3FM-d","colab":{}},"source":["# 오버피팅이 되지 않은 상태에서 L2나 dropout하면 성능이 더 떨어짐\n","class CNN(nn.Module):\n","  def __init__(self):\n","    # super는 CNN 클래스의 부모 클래스인 nn.Module을 초기화\n","    super(CNN, self).__init__()\n","    self.layer = nn.Sequential(\n","        # 1, 28, 28 -> 16, 28, 28\n","        nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 5),\n","        nn.ReLU(),\n","        # 16, 24, 24 -> 32, 20, 20\n","        nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5),\n","        nn.ReLU(),\n","        #nn.Dropout2d(0.2),\n","        # 32, 20, 20 -> 32, 10, 10\n","        nn.MaxPool2d(kernel_size = 2, stride = 2),\n","        # 32, 10, 10 -> 64, 6, 6\n","        nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 5),\n","        nn.ReLU(),\n","        # 64, 3, 3\n","        nn.MaxPool2d(kernel_size = 2, stride = 2)\n","    )\n","\n","# batch norm\n","'''\n","nn.Conv2d(32,64,3,padding=1), # 14 x 14\n","            nn.BatchNorm2d(64),\n","    이런 식으로 합성곱층 위의 out_channels과 똑같이 해주면 됨'''\n","    \n","    self.fc_layer = nn.Sequential(\n","        nn.Linear(64 * 3 * 3, 100), # 64 * 3 * 3 -> 100\n","        nn.ReLU(),\n","           nn.Linear(100, 10) # 100 -> 10\n","    )\n","\n","    # W initialization\n","'''for m in self.modules():\n","            # 만약 그 모듈이 nn.Conv2d인 경우\n","            if isinstance(m, nn.Conv2d):\n","                \n","                # 작은 숫자로 초기화하는 방법\n","                # 가중치를 평균 0, 편차 0.02로 초기화합니다.\n","                # 편차를 0으로 초기화합니다.\n","                m.weight.data.normal_(0.0, 0.02)\n","                m.bias.data.fill_(0)\n","                \n","                # Xavier Initialization\n","                # 모듈의 가중치를 xavier normal로 초기화합니다.\n","                # 편차를 0으로 초기화합니다.\n","                init.xavier_normal(m.weight.data)\n","                m.bias.data.fill_(0)\n","                \n","                \n","                # Kaming Initialization\n","                # 모듈의 가중치를 kaming he normal로 초기화합니다.\n","                # 편차를 0으로 초기화합니다.\n","                init.kaiming_normal_(m.weight.data)\n","                m.bias.data.fill_(0)\n","            \n","            # 만약 그 모듈이 nn.Linear인 경우\n","            elif isinstance(m, nn.Linear):\n","                \n","                # 작은 숫자로 초기화하는 방법\n","                # 가중치를 평균 0, 편차 0.02로 초기화합니다.\n","                # 편차를 0으로 초기화합니다.\n","                m.weight.data.normal_(0.0, 0.02)\n","                m.bias.data.fill_(0)\n","                \n","                # Xavier Initialization\n","                # 모듈의 가중치를 xavier normal로 초기화합니다.\n","                # 편차를 0으로 초기화합니다.\n","                init.xavier_normal(m.weight.data)\n","                m.bias.data.fill_(0)\n","                \n","                \n","                # Kaming Initialization\n","                # 모듈의 가중치를 kaming he normal로 초기화합니다.\n","                # 편차를 0으로 초기화합니다.\n","                init.kaiming_normal_(m.weight.data)\n","                m.bias.data.fill_(0)'''\n","\n","  def forward(self, x):\n","    out = self.layer(x) # Sequential 연산 차례대로 실행\n","    out = out.view(batch_size , -1) # 텐서를 batch_size, 나머지로 바꿔줌\n","\n","    out = self.fc_layer(out)\n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PfBRGqWpGINW"},"source":["## loss & minimize"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1578,"status":"ok","timestamp":1572666372452,"user":{"displayName":"김태웅","photoUrl":"","userId":"06196795162879697734"},"user_tz":-540},"id":"p0ucP9okJ1FK","outputId":"15a6f5bd-e2f6-41a1-f1da-de1f0e47bcd3","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# gpu가 사용가능하면 device를 gpu로, 아니면 cpu\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","# 모델을 지정한 장치로 올림\n","model = CNN().to(device)\n","\n","# 손실함수는 crossentropy\n","loss_func = nn.CrossEntropyLoss()\n","\n","# 최적화는 adam\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n","# L2\n","# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.1)\n","\n","'''# 지정한 스텝 단위로 학습률에 감마를 곱해 학습률을 감소시킵니다.\n","#scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma= 0.99)       \n","\n","# 지정한 스텝 지점(예시에서는 10,30,80)마다 학습률에 감마를 곱해줍니다.\n","#scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10,30,80], gamma= 0.1)  \n","\n","# 매 epoch마다 학습률에 감마를 곱해줍니다.\n","#scheduler = lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)                             \n","\n","# https://pytorch.org/docs/stable/optim.html?highlight=lr_scheduler#torch.optim.lr_scheduler.ReduceLROnPlateau\n","# 지정한 메트릭으로 측정한 값이 더 나아지지 않으면 학습률을 감소시킵니다. ex) 정확도, dice score 등등\n","# 이 스케쥴러에는 다양한 인자가 들어가는데 각각의 역할은 도큐먼트를 참고 바랍니다.\n","# 여기서는 patience 즉, 지정한 값이 줄어들지 않을때 몇 epoch 만큼을 지켜볼 것인지를 1로 낮춰놨기 때문에 매 epoch 마다 학습률이 감소하는것을 확인할 수 있습니다.\n","scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,threshold=1,patience=1,mode='min')    \n","\n","# 참고 https://www.geeksforgeeks.org/python-dir-function/\n","print(dir(scheduler))\n","print(dir(optimizer))'''"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2KVIaqc_KOtz"},"source":["## training"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":71969,"status":"ok","timestamp":1572669870079,"user":{"displayName":"김태웅","photoUrl":"","userId":"06196795162879697734"},"user_tz":-540},"id":"fmSxdRSEKh0C","outputId":"29c0ad17-b84e-480b-eb88-c4734ca70890","colab":{"base_uri":"https://localhost:8080/","height":199}},"source":["loss_arr = []\n","for i in range(num_epoch):\n","  for j, [image, label] in enumerate(train_loader):\n","    x = image.to(device)\n","    y = label.to(device)\n","\n","    optimizer.zero_grad()\n","    output = model.forward(x)\n","    loss = loss_func(output, y)\n","    loss.backward()\n","    optimizer.step()\n","    if j % 1000 == 0:\n","      print(loss)\n","      loss_arr.append(loss.cpu().detach().numpy())\n","\n","    '''\n","    # ReduceLRONPlateau 만 해당됩니다. 이 코드에서는 손실이 줄어들지 않으면 학습률을 낮추도록 만들어놨습니다.\n","    scheduler.step(loss)\n","    '''"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.0324, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.0523, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.0246, device='cuda:0', grad_fn=<NllLossBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"U6WaywOcLe0A"},"source":["## training loss visualization"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":71652,"status":"ok","timestamp":1572666442546,"user":{"displayName":"김태웅","photoUrl":"","userId":"06196795162879697734"},"user_tz":-540},"id":"iqyultzxMLCK","outputId":"04c89a16-32c6-4560-abee-c62192113fdf","colab":{"base_uri":"https://localhost:8080/","height":265}},"source":["plt.plot(loss_arr)\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXc5TcAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rn-T2Nx_MLYK"},"source":["## test data acc"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":7884,"status":"ok","timestamp":1572666532837,"user":{"displayName":"김태웅","photoUrl":"","userId":"06196795162879697734"},"user_tz":-540},"id":"Bd5bC1nOMj3C","outputId":"932b000f-93eb-4ce0-e035-2f69d04535f5","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# 맞은 갯수, 전체 개수를 저장할 변수를 지정\n","correct=  0\n","total = 0\n","\n","# batch norm나 드롭아웃을 썼다면 모델을 eval모드로 바꿔야 함.\n","# model.train() # batch norm, dropout을 사용할 때\n","# model.eval() # batch norm, dropout을 사용하고 실제 예측할 때\n","\n","# inference model\n","with torch.no_grad():\n","  # 테스트 로더에서 이미지와 정답을 불러옴\n","  for image, label in test_loader:\n","\n","    # 두 데이터 모두 장치에 올림\n","    x = image.to(device)\n","    y = label.to(device)\n","\n","    # 모델에 데이터를 넣고 결과값을 얻음\n","    output = model.forward(x)\n","\n","    # torch.max로 최대값과 최대값 인덱스를 뽑아냄\n","    # 최대값은 필요없어서 인덱스만 사용\n","    _, output_index = torch.max(output, 1)\n","\n","    # 전체 개수는 라벨의 개수로 더해줌\n","    total += label.size(0) # == label.size[0]  아까 drop last로 짤렸을 수도 있어서\n","\n","    # 모델 결과의 최대값 인덱스와 라벨이 일치하는 개수를 correct에 더해줌\n","    correct += (output_index == y).sum().float()\n","\n","  print('acc: {}%'.format(100 * correct / total))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["acc: 98.81978607177734%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":823,"status":"ok","timestamp":1572666664582,"user":{"displayName":"김태웅","photoUrl":"","userId":"06196795162879697734"},"user_tz":-540},"id":"GkZf0nloNSOO","outputId":"258ba132-95aa-47fe-aaa6-9b5ab0578291","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["torch.max(torch.Tensor([[1, 2],\n","                        [3, 4]]), 1) # 1이니까 -> 이쪽 방향"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.return_types.max(values=tensor([3., 4.]), indices=tensor([1, 1]))"]},"metadata":{"tags":[]},"execution_count":68}]}]}